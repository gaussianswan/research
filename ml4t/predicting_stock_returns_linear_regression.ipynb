{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Stock Returns - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "YEAR = 252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('data/data.h5') as store:\n",
    "    data = (store['model_data']\n",
    "            .dropna()\n",
    "            .drop(['open', 'close', 'low', 'high'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index.names = ['symbol', 'date']\n",
    "data = data.drop([c for c in data.columns if 'lag' in c], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the investment universe\n",
    "data = data[data.dollar_vol_rank<100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.filter(like='target')\n",
    "X = data.drop(y.columns, axis=1)\n",
    "X = X.drop(['dollar_vol', 'dollar_vol_rank', 'volume', 'consumer_durables'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom MultipleTimeSeriesCV object to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleTimeSeriesCV: \n",
    "\n",
    "    def __init__(self, n_splits = 3, train_period_length = 126, test_period_length = 21, lookahead = None, shuffle = False) -> None:\n",
    "        self.n_splits = n_splits\n",
    "        self.lookahead = lookahead\n",
    "        self.test_length = test_period_length\n",
    "        self.train_length = train_period_length\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def split(self, X, y = None, groups = None): \n",
    "        unique_dates = X.index.get_level_values('date').unique()\n",
    "        days = sorted(unique_dates, reverse=True)\n",
    "\n",
    "        split_idx = []\n",
    "        for i in range(self.n_splits):\n",
    "            test_end_idx = i * self.test_length\n",
    "            test_start_idx = test_end_idx + self.test_length\n",
    "            train_end_idx = test_start_idx + + self.lookahead - 1\n",
    "            train_start_idx = train_end_idx + self.train_length + self.lookahead - 1\n",
    "            split_idx.append([train_start_idx, train_end_idx,\n",
    "                              test_start_idx, test_end_idx])\n",
    "\n",
    "        dates = X.reset_index()[['date']]\n",
    "        for train_start, train_end, test_start, test_end in split_idx:\n",
    "            train_idx = dates[(dates.date > days[train_start])\n",
    "                              & (dates.date <= days[train_end])].index\n",
    "            test_idx = dates[(dates.date > days[test_start])\n",
    "                             & (dates.date <= days[test_end])].index\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(list(train_idx))\n",
    "            yield train_idx, test_idx\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return self.n_splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_period_length = 63\n",
    "test_period_length = 10\n",
    "n_splits = int(3 * YEAR/test_period_length)\n",
    "lookahead =1 \n",
    "\n",
    "cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                          test_period_length=test_period_length,\n",
    "                          lookahead=lookahead,\n",
    "                          train_period_length=train_period_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = f'target_{lookahead}d'\n",
    "lr_predictions, lr_scores = [], []\n",
    "lr = LinearRegression()\n",
    "for i, (train_idx, test_idx) in enumerate(cv.split(X), 1):\n",
    "    X_train, y_train, = X.iloc[train_idx], y[target].iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y[target].iloc[test_idx]\n",
    "    lr.fit(X=X_train, y=y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    preds = y_test.to_frame('actuals').assign(predicted=y_pred)\n",
    "    preds_by_day = preds.groupby(level='date')\n",
    "    scores = pd.concat([preds_by_day.apply(lambda x: spearmanr(x.predicted,\n",
    "                                                               x.actuals)[0] * 100)\n",
    "                        .to_frame('ic'),\n",
    "                        preds_by_day.apply(lambda x: np.sqrt(mean_squared_error(y_pred=x.predicted,\n",
    "                                                                                y_true=x.actuals)))\n",
    "                        .to_frame('rmse')], axis=1)\n",
    "\n",
    "    lr_scores.append(scores)\n",
    "    lr_predictions.append(preds)\n",
    "\n",
    "lr_scores = pd.concat(lr_scores)\n",
    "lr_predictions = pd.concat(lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores.to_hdf('data/data.h5', 'lr/scores')\n",
    "lr_predictions.to_hdf('data/data.h5', 'lr/predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
