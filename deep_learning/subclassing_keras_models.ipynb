{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to subclass keras models\n",
    "\n",
    "A lot of times, we may want to create our own complicated models. We can subclass the `keras.Model` class which exposes the `fit()`, `evaluate()`, and `predict()` methods. We can do things like get the layers in the model and also save it and load things. Let's get into it. \n",
    "\n",
    "A rule of thumb: If you need to call the `fit()` method on what you are making, then you should subclass the `Model` class. If not, then you should probably use a `Layer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 23:41:22.579380: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-11 23:41:22.581232: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-11 23:41:22.616202: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-11 23:41:22.617009: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-11 23:41:23.183348: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(keras.layers.Layer): \n",
    "\n",
    "    def __init__(self, units = 32, input_dim = 32): \n",
    "        super().__init__()\n",
    "\n",
    "        self.w = self.add_weight(\n",
    "            shape = (input_dim, units), initializer='random_normal', trainable=True\n",
    "        )\n",
    "\n",
    "        self.b = self.add_weight(shape = (units, ), initializer='zeros', trainable=True)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-0.08255447, -0.01942443],\n",
       "       [-0.08255447, -0.01942443]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = tf.ones((2, 2))\n",
    "linear_layer = Linear(units = 2, input_dim=2)\n",
    "linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer): \n",
    "    \"\"\"Maps MNIST digits to a triplet of (z_mean, z_log_var, z)\n",
    "\n",
    "    Args:\n",
    "        layers (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim = 32, intermediate_dim = 64, name = 'encoder', **kwargs): \n",
    "        super().__init__(name = name, **kwargs)\n",
    "\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation = 'relu')\n",
    "        self.dense_mean = layers.Dense(latent_dim)\n",
    "        self.dense_log_var = layers.Dense(latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "\n",
    "    def call(self, inputs): \n",
    "        x = self.dense_proj(inputs)\n",
    "        z_mean = self.dense_mean(x)\n",
    "        z_log_var = self.dense_log_var(x)\n",
    "        z = self.sampling((z_mean, z_log_var))\n",
    "        return z_mean, z_log_var, z\n",
    "    \n",
    "class Decoder(layers.Layer): \n",
    "\n",
    "    def __init__(self, original_dim, intermediate_dim = 64, name = 'decoder', **kwargs): \n",
    "        super().__init__(name = name, **kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation = 'relu')\n",
    "        self.dense_output = layers.Dense(original_dim, activation = 'sigmoid') # This is what we are outputting \n",
    "\n",
    "    def call(self, inputs): \n",
    "        x = self.dense_proj(inputs)\n",
    "        return self.dense_output(x)\n",
    "    \n",
    "class VariationalAutoEncoder(keras.Model): \n",
    "\n",
    "    \"\"\"\n",
    "    Combines the encoder and decoder into one end-to-end model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, original_dim, intermediate_dim = 64, latent_dim = 32, name = 'autoencoder', **kwargs): \n",
    "        super().__init__(name = name, **kwargs)\n",
    "\n",
    "        self.original_dim = original_dim\n",
    "        self.encoder = Encoder(latent_dim=latent_dim, intermediate_dim=intermediate_dim)\n",
    "        self.decoder = Decoder(original_dim=original_dim, intermediate_dim=intermediate_dim)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "\n",
    "        kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "        self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing a training loop on mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = 784\n",
    "vae = VariationalAutoEncoder(original_dim=original_dim, intermediate_dim=64, latent_dim=32)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "mse_loss_fn = keras.losses.MeanSquaredError()\n",
    "loss_metric = keras.metrics.Mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), _ = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "\n",
    "# We create a train dataset where we take the mnist data and batch it into 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, we have 60000 examples of digits that are 28 by 28. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 23:41:28.381410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [60000,784]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-11 23:41:28.381622: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [60000,784]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: mean loss = 0.3301\n",
      "step 100: mean loss = 0.1255\n",
      "step 200: mean loss = 0.0991\n",
      "step 300: mean loss = 0.0892\n",
      "step 400: mean loss = 0.0842\n",
      "step 500: mean loss = 0.0809\n",
      "step 600: mean loss = 0.0787\n",
      "step 700: mean loss = 0.0771\n",
      "step 800: mean loss = 0.0760\n",
      "step 900: mean loss = 0.0749\n",
      "step 0: mean loss = 0.0747\n",
      "step 100: mean loss = 0.0740\n",
      "step 200: mean loss = 0.0735\n",
      "step 300: mean loss = 0.0730\n",
      "step 400: mean loss = 0.0727\n",
      "step 500: mean loss = 0.0723\n",
      "step 600: mean loss = 0.0720\n",
      "step 700: mean loss = 0.0717\n",
      "step 800: mean loss = 0.0715\n",
      "step 900: mean loss = 0.0712\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "for epoch in range(EPOCHS): \n",
    "\n",
    "    for step, x_batch_train in enumerate(train_dataset): \n",
    "        with tf.GradientTape() as tape: \n",
    "            reconstructed = vae(x_batch_train)\n",
    "\n",
    "            loss = mse_loss_fn(x_batch_train, reconstructed)\n",
    "            loss += sum(vae.losses)\n",
    "\n",
    "        grads = tape.gradient(loss, vae.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "        loss_metric(loss)\n",
    "\n",
    "        if step % 100 == 0: \n",
    "            print(\"step %d: mean loss = %.4f\" % (step, loss_metric.result()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 784), dtype=float32, numpy=\n",
       "array([[0.00273651, 0.00332379, 0.00437694, ..., 0.00553383, 0.00263036,\n",
       "        0.00246718],\n",
       "       [0.01085568, 0.01114361, 0.01539413, ..., 0.01720259, 0.01066354,\n",
       "        0.00600129],\n",
       "       [0.01805389, 0.01679887, 0.00758007, ..., 0.00942108, 0.00831249,\n",
       "        0.00986585],\n",
       "       ...,\n",
       "       [0.02457168, 0.02050058, 0.03342368, ..., 0.02863369, 0.02739112,\n",
       "        0.02686335],\n",
       "       [0.00966561, 0.00497065, 0.00836083, ..., 0.00921608, 0.00758252,\n",
       "        0.00725008],\n",
       "       [0.00517703, 0.00732105, 0.00587739, ..., 0.00726794, 0.00401937,\n",
       "        0.00605658]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 784), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have done all of the above here by using the `fit` method which is exposed to us because we did the model subclassing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_2 = VariationalAutoEncoder(\n",
    "    original_dim=original_dim, \n",
    "    intermediate_dim=10, \n",
    "    latent_dim=10, \n",
    "    name='autoencoder_2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0904\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.0680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21784e7a90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "vae_2.compile(optimizer = optimizer, loss = keras.losses.MeanSquaredError())\n",
    "vae_2.fit(x_train, x_train, epochs = 2, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "There are a couple of things that we can conclude from this exercise \n",
    "* Subclassing layers should be done when you want to introduce a certain part of your network to be used for later\n",
    "    * You are going to put in parameters in the `__init__` method and make sure you run `super().__init__(**kwargs)` at the top\n",
    "    * You have to overwrite the `call()` method which takes some input and sends out some output. This output can be whatever you want it to be\n",
    "* Subclassing models should be done when you want to build an entire end to end pipeline with smaller components\n",
    "    * The `Sequential` model is a subclass of this general `Model` class\n",
    "    * We also update the `call()` method of this class to use our individual units\n",
    "    * The methods of `fit` and `save` methods are exposed for us here which is great. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
